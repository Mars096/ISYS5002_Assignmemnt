{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sandbox_Assignment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+OZOyMo6z3sqMOUoMWd62",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mars096/ISYS5002_Assignmemnt/blob/main/Sandbox_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEv2YUu3ZIXC"
      },
      "source": [
        "#Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X1Pi2YQZMIK"
      },
      "source": [
        "###By Mars Chen 20628055"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R2EbjEAauqF"
      },
      "source": [
        "**In order to accomplish this task, my design for achieving this programming result is: 1. Know keywords (such as what is ticker symbol) 2. Build website url based on Yahoo Finance website. 3. Find the file page and the form 4 about administrative staff. Copy the table and grab the data of each row in the table. 5. Normalize the data, convert \"M\" into millions and \"k\" into thousands, and grab everyone's salary. 6. Establish a tax algorithm, use the algorithm to calculate the amount of tax payable, and add the column \"tax\" to the original table**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb60Gj_2tpPL"
      },
      "source": [
        "# Initial Algorithm\n",
        "\n",
        "1. User input ticker symbol\n",
        "2. Use ticker to get profile page\n",
        "3. Copied the table\n",
        "4. For each row of the table\n",
        "5. Process a row to extract pay\n",
        "6. Find the last character to determin mutiplier\n",
        "7. Calculate salary, pay*multiplier\n",
        "8. Calculate the income tax\n",
        "\n",
        "Note:\n",
        "1. Need to validate the ticker,but for now I will assume the user type in a correct ticker\n",
        "2. Still need to work out where I save the income tax "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXK_a77I0gYE"
      },
      "source": [
        "# Usually run of Google Coolab, so install unique packages\n",
        "!pip install kora -q\n",
        "\n",
        "#load packages\n",
        "from bs4 import BeautifulSoup\n",
        "from kora.selenium import wd\n",
        "import pandas as pd\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag1JC_MqcX0B"
      },
      "source": [
        "**Enter the existing website crawling algorithm and data input algorithm to serve the next steps**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZqXI4gzyEvz"
      },
      "source": [
        "def make_url():\n",
        "  #Step1: User input ticker symbol\n",
        "  ticker_symbol= input(\"Please input ticker symbol\")\n",
        "  #print(ticker_symbol)\n",
        "  example_url= 'https://au.finance.yahoo.com/quote/{}/profile?p={}'\n",
        "  result = example_url.format(ticker_symbol, ticker_symbol)\n",
        "  return result"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NOI5AOhc7Pd"
      },
      "source": [
        "**Create a URL, enter \"ticker symbol\" to find the corresponding company's Yahoo Finance website, and get the results of the website. You can manually test to see if the URL is created correctly.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn3laxiN-HEc"
      },
      "source": [
        "def get_first_3_cells(row):\n",
        "  cells = row.find_all('td')\n",
        "  name = cells[0].text\n",
        "  title = cells[1].text\n",
        "  pay = cells[2].text\n",
        "  return {'name':name, 'title':title, 'pay':pay}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIeDaG0CddNd"
      },
      "source": [
        "**This function creates tables and names the value represented by each table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1TuBR9bBGtG"
      },
      "source": [
        "def get_exec_records(soup):\n",
        "  table = soup.find('table')\n",
        "  body = table.find('tbody')\n",
        "  rows = body.find_all('tr')\n",
        "\n",
        "  exec_records=[]\n",
        "  for row in rows:\n",
        "    result = get_first_3_cells(row)\n",
        "    exec_records.append(result)\n",
        "  return exec_records"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMqMvLSvd8zG"
      },
      "source": [
        "**To capture website data through soup, the specific method is to find the code about the table in the design code of the original website, and name it as the representation item (tbody, tr, etc.) in the source code**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEEo4j9nQLf3"
      },
      "source": [
        "def get_salary(rec)\n",
        "  pay = rec['pay']\n",
        "  last_char = pay[-1]\n",
        "  num_part = pay[0:-1]\n",
        "  if last_char == 'M':\n",
        "    salary = float(num_part)*1000000\n",
        "  elif last_char == 'k':\n",
        "    salary = float(num_part)*1000\n",
        "  else:\n",
        "    salary = 0\n",
        "  return salary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrAwJdy-eu3I"
      },
      "source": [
        "**The expression of salary in the original form has become normalized, because there are simplified expressions of \"M\" and \"K\" in the original wages, and standardizing them into Arabic numerals is more intuitive and conducive to tax calculations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1NdU4FwYKeA"
      },
      "source": [
        "def calculate_tax(income):\n",
        "\n",
        "  if income <= 18200:\n",
        "    tax_payable = 0\n",
        "  elif 18200 < income <= 45000:\n",
        "    tax_payable = 0.19 * (income - 18200)\n",
        "  elif 45000 < income < 120000:\n",
        "    tax_payable = 5092 + 0.32 * (income - 45000)\n",
        "  elif 120000 < income < 180000:\n",
        "    tax_payable = 29467 + 0.37 * (income - 120000)\n",
        "  elif 180000 < income:\n",
        "    tax_payable = 51667 + 0.45 * (income - 180000)\n",
        "\n",
        "  return tax_payable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDvr6Q-2fRqB"
      },
      "source": [
        "**For the calculation of tax, it calculates how much tax each person should pay for his salary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePYFE_PHC6_1"
      },
      "source": [
        "# Get URL\n",
        "url= make_url()\n",
        "wd.get(url)\n",
        "soup = BeautifulSoup(wd.page_source,\"html.parser\")\n",
        "get_exec_records(soup)\n",
        "\n",
        "for r in records:\n",
        "  result = get_salary(record)\n",
        "  income_tax = calculate_tax(result)\n",
        "  record['tax']=income_tax\n",
        "\n",
        "#create a pandas dataframe(because recall in a earlier notebook a data frame is easy to save as csv)\n",
        "execs_df = pd.dataframe.from_records(records)\n",
        "execs_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXElr2aXPQ-1"
      },
      "source": [
        "\n",
        "**Here I encountered a problem that get_exec_records(soup) has AttributeError:'NoneType' object has no attribute'find', but I don't know how to fix this error, thanks, Michael**\n"
      ]
    }
  ]
}